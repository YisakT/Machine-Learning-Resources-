{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we're covering in the Scikit-Learn Introduction\n",
    "\n",
    "This notebook outlines the content convered in the Scikit-Learn Introduction.\n",
    "\n",
    "It's a quick stop to see all the Scikit-Learn functions and modules for each section outlined.\n",
    "\n",
    "What we're covering follows the following diagram detailing a Scikit-Learn workflow.\n",
    "\n",
    "<img src=\"../images/sklearn-workflow-title.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Standard library imports\n",
    "\n",
    "For all machine learning projects, you'll often see these libraries (Matplotlib, NumPy and pandas) imported at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling inline display of matplotlib plots within the Jupyter Notebook\n",
    "# '%matplotlib inline' is a magic function in IPython that renders the plots in a cell output within the Jupyter notebook itself.\n",
    "# Without this line, plots might open in a new window or not display at all.\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing the matplotlib.pyplot module\n",
    "# This module provides a MATLAB-like plotting framework, which is widely used for plotting graphs and charts in Python.\n",
    "# 'plt' is a commonly used alias for matplotlib.pyplot.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing the numpy module\n",
    "# NumPy is a fundamental package for scientific computing in Python, providing support for arrays, mathematical functions, and more.\n",
    "# 'np' is a widely used abbreviation for NumPy, making it more convenient to refer to in the code.\n",
    "import numpy as np\n",
    "\n",
    "# Importing the pandas module\n",
    "# pandas is a powerful data manipulation and analysis library for Python, providing DataFrame objects for handling tabular data.\n",
    "# 'pd' is the conventional alias for pandas, used for convenience in referencing the library.\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 2 datasets for demonstration purposes.\n",
    "* `heart_disease` - a classification dataset (predicting whether someone has heart disease or not)\n",
    "* `boston_df` - a regression dataset (predicting the median house prices of cities in Boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and Preparing Classification and Regression Datasets\n",
    "\n",
    "# Classification Dataset: Heart Disease\n",
    "\n",
    "# Loading the heart disease dataset into a pandas DataFrame.\n",
    "# The dataset is read from a CSV file located at 'heart-disease.csv'.\n",
    "# This dataset is typically used for classification tasks.\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "\n",
    "# Regression Dataset: California Housing\n",
    "\n",
    "# Importing the fetch_california_housing function from sklearn.datasets.\n",
    "# This function provides access to the California housing dataset,\n",
    "# which is commonly used for regression tasks.\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Fetching the California housing dataset.\n",
    "# The dataset is loaded as a Bunch object (similar to a dictionary).\n",
    "california_housing = fetch_california_housing()\n",
    "\n",
    "# Converting the California housing dataset from a Bunch object to a pandas DataFrame.\n",
    "# The 'data' attribute contains the features, and 'feature_names' attribute provides the column names.\n",
    "# Creating a DataFrame 'california_housing_df' with features and column names.\n",
    "california_housing_df = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
    "\n",
    "# Adding the target variable to the DataFrame.\n",
    "# The 'target' attribute in the California housing dataset contains the dependent variable (housing prices).\n",
    "# It's added as a new column named 'target' in the DataFrame.\n",
    "california_housing_df[\"target\"] = california_housing.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Heart Disease Dataset into Features and Target Variable\n",
    "\n",
    "# Creating the features matrix (X) from the heart_disease DataFrame.\n",
    "# This is done by dropping the 'target' column which is our dependent variable.\n",
    "# The 'drop' method removes the specified column ('target') from the DataFrame.\n",
    "# 'axis=1' indicates that we are dropping a column, not a row.\n",
    "# The resulting DataFrame, assigned to X, contains only the independent variables (features).\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Creating the target vector (y) from the heart_disease DataFrame.\n",
    "# The target variable is what we are trying to predict or classify.\n",
    "# In this case, 'y' is the 'target' column from the heart_disease DataFrame,\n",
    "# which represents the presence or absence of heart disease.\n",
    "y = heart_disease[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Dataset into Training and Test Sets\n",
    "\n",
    "# Importing the train_test_split function from sklearn.model_selection.\n",
    "# This function is used to randomly split the dataset into training and test subsets.\n",
    "# It's a common practice in machine learning to evaluate the performance of a model.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the features matrix (X) and target vector (y) into training and test sets.\n",
    "# The 'train_test_split' function returns four subsets:\n",
    "# X_train: part of the features used for training the model.\n",
    "# X_test: part of the features used for testing the model.\n",
    "# y_train: part of the target variable corresponding to X_train, used for training.\n",
    "# y_test: part of the target variable corresponding to X_test, used for evaluating the model.\n",
    "# By default, the function splits the data into 75% for training and 25% for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pick a model/estimator (to suit your problem)\n",
    "To pick a model we use the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map.png\" width=400/>\n",
    "\n",
    "**Note:** Scikit-Learn refers to machine learning models and algorithms as estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and Instantiating a Random Forest Classifier for Classification Tasks\n",
    "\n",
    "# Importing the RandomForestClassifier from sklearn.ensemble.\n",
    "# RandomForestClassifier is an ensemble learning method used for classification tasks.\n",
    "# It operates by constructing a multitude of decision trees at training time \n",
    "# and outputting the class that is the mode of the classes (classification) \n",
    "# of the individual trees.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Creating an instance of the RandomForestClassifier.\n",
    "# Here, 'clf' (short for 'classifier') is instantiated as a RandomForestClassifier.\n",
    "# Without any parameters, it will use the default settings of the classifier.\n",
    "# You can customize it by passing parameters like n_estimators (number of trees),\n",
    "# max_depth (maximum depth of each tree), and others, according to your dataset and task.\n",
    "clf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and Instantiating a Random Forest Regressor for Regression Tasks\n",
    "\n",
    "# Importing the RandomForestRegressor from sklearn.ensemble.\n",
    "# RandomForestRegressor is an ensemble learning method primarily used for regression tasks.\n",
    "# Similar to the classifier, it operates by constructing a multitude of decision trees at training time.\n",
    "# For regression tasks, it predicts the output based on the average or mean of the outputs of individual trees.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Creating an instance of the RandomForestRegressor.\n",
    "# Here, 'model' is instantiated as a RandomForestRegressor.\n",
    "# The default settings are used for this instance, but it can be customized with various parameters.\n",
    "# Parameters like n_estimators (number of trees), max_depth (maximum depth of each tree),\n",
    "# and others can be specified to tailor the model to specific datasets and regression tasks.\n",
    "model = RandomForestRegressor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the model to the data and make a prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1], dtype=int64),\n",
       " array([[0.91, 0.09],\n",
       "        [0.45, 0.55],\n",
       "        [0.51, 0.49],\n",
       "        [0.85, 0.15],\n",
       "        [0.25, 0.75],\n",
       "        [0.05, 0.95],\n",
       "        [0.25, 0.75],\n",
       "        [0.97, 0.03],\n",
       "        [0.98, 0.02],\n",
       "        [0.52, 0.48],\n",
       "        [0.15, 0.85],\n",
       "        [0.69, 0.31],\n",
       "        [0.06, 0.94],\n",
       "        [0.86, 0.14],\n",
       "        [0.05, 0.95],\n",
       "        [0.01, 0.99],\n",
       "        [0.  , 1.  ],\n",
       "        [0.86, 0.14],\n",
       "        [0.95, 0.05],\n",
       "        [0.95, 0.05],\n",
       "        [0.46, 0.54],\n",
       "        [0.93, 0.07],\n",
       "        [0.31, 0.69],\n",
       "        [0.29, 0.71],\n",
       "        [0.36, 0.64],\n",
       "        [0.28, 0.72],\n",
       "        [0.2 , 0.8 ],\n",
       "        [0.23, 0.77],\n",
       "        [0.9 , 0.1 ],\n",
       "        [0.21, 0.79],\n",
       "        [0.95, 0.05],\n",
       "        [0.87, 0.13],\n",
       "        [0.98, 0.02],\n",
       "        [0.65, 0.35],\n",
       "        [0.42, 0.58],\n",
       "        [0.94, 0.06],\n",
       "        [0.34, 0.66],\n",
       "        [0.29, 0.71],\n",
       "        [0.35, 0.65],\n",
       "        [0.14, 0.86],\n",
       "        [0.13, 0.87],\n",
       "        [0.18, 0.82],\n",
       "        [0.16, 0.84],\n",
       "        [0.25, 0.75],\n",
       "        [0.25, 0.75],\n",
       "        [0.72, 0.28],\n",
       "        [0.36, 0.64],\n",
       "        [0.02, 0.98],\n",
       "        [0.89, 0.11],\n",
       "        [0.95, 0.05],\n",
       "        [0.79, 0.21],\n",
       "        [0.82, 0.18],\n",
       "        [0.17, 0.83],\n",
       "        [0.26, 0.74],\n",
       "        [0.95, 0.05],\n",
       "        [0.89, 0.11],\n",
       "        [0.69, 0.31],\n",
       "        [0.  , 1.  ],\n",
       "        [0.89, 0.11],\n",
       "        [0.99, 0.01],\n",
       "        [0.78, 0.22],\n",
       "        [0.04, 0.96],\n",
       "        [0.76, 0.24],\n",
       "        [0.55, 0.45],\n",
       "        [0.07, 0.93],\n",
       "        [0.87, 0.13],\n",
       "        [0.65, 0.35],\n",
       "        [0.47, 0.53],\n",
       "        [0.15, 0.85],\n",
       "        [0.14, 0.86],\n",
       "        [0.19, 0.81],\n",
       "        [0.08, 0.92],\n",
       "        [0.42, 0.58],\n",
       "        [0.13, 0.87],\n",
       "        [0.78, 0.22],\n",
       "        [0.07, 0.93]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model and Making Predictions\n",
    "\n",
    "# Fitting the Model\n",
    "# The 'fit' method is used to train the model using the training data.\n",
    "# It adjusts the parameters of the model (clf) so it best fits the data.\n",
    "# Here, clf.fit(X_train, y_train) trains the RandomForestClassifier 'clf' \n",
    "# using the features (X_train) and the target (y_train) from the training set.\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making Standard Predictions\n",
    "# After the model is trained, you can use the 'predict' method to make predictions.\n",
    "# 'clf.predict(X_test)' uses the features from the test set (X_test) to predict the target values.\n",
    "# The predicted target values are stored in 'y_preds'.\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Making Predictions with Probabilities (specific to classification models)\n",
    "# The 'predict_proba' method is used to predict class probabilities for classification models.\n",
    "# It returns the probability of the test data belonging to each class.\n",
    "# In the case of RandomForestClassifier, it gives the mean predicted class probabilities\n",
    "# of the trees in the forest.\n",
    "# The probabilities for the test set (X_test) are stored in 'y_probs'.\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# Viewing Predictions and Probabilities\n",
    "# Printing 'y_preds' and 'y_probs' to see the predictions and the associated probabilities.\n",
    "# 'y_preds' shows the predicted class labels, while 'y_probs' shows the probability estimates.\n",
    "y_preds, y_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the model\n",
    "\n",
    "Every Scikit-Learn model has a default metric which is accessible through the `score()` function.\n",
    "\n",
    "However there are a range of different evaluation metrics you can use depending on the model you're using.\n",
    "\n",
    "A full list of evaluation metrics can be [found in the documentation](https://scikit-learn.org/stable/modules/model_evaluation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289473684210527"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All models/estimators have a score() function\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81967213 0.86885246 0.81967213 0.78333333 0.76666667]\n",
      "[0.82857143 0.93333333 0.80645161 0.81818182 0.76923077]\n"
     ]
    }
   ],
   "source": [
    "# Evaluting a model using cross-validation is possible with cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# scoring=None means default score() metric is used\n",
    "print(cross_val_score(estimator=clf, \n",
    "                      X=X, \n",
    "                      y=y, \n",
    "                      cv=5, # use 5-fold cross-validation\n",
    "                      scoring=None)) \n",
    "\n",
    "# Evaluate a model with a different scoring method\n",
    "print(cross_val_score(estimator=clf, \n",
    "                      X=X, \n",
    "                      y=y,\n",
    "                      cv=5, # use 5-fold cross-validation\n",
    "                      scoring=\"precision\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8289473684210527\n",
      "0.8268292682926829\n",
      "[[28  7]\n",
      " [ 6 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81        35\n",
      "           1       0.83      0.85      0.84        41\n",
      "\n",
      "    accuracy                           0.83        76\n",
      "   macro avg       0.83      0.83      0.83        76\n",
      "weighted avg       0.83      0.83      0.83        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Different classification metrics\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_preds))\n",
    "\n",
    "# Reciver Operating Characteristic (ROC curve)/Area under curve (AUC)\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_probs[:, 1])\n",
    "print(roc_auc_score(y_test, y_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.801891020387404\n",
      "Mean Absolute Error (MAE): 0.32951328255813966\n",
      "Mean Squared Error (MSE): 0.2579791311908462\n"
     ]
    }
   ],
   "source": [
    "# Different regression metrics using the California Housing Dataset\n",
    "\n",
    "# Make predictions first\n",
    "# Using the California housing dataset DataFrame for the regression model\n",
    "X = california_housing_df.drop(\"target\", axis=1)\n",
    "y = california_housing_df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and train the RandomForestRegressor model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using various regression metrics\n",
    "\n",
    "# R^2 (pronounced r-squared) or coefficient of determination\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R^2 Score:\", r2_score(y_test, y_preds))\n",
    "\n",
    "# Mean absolute error (MAE)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, y_preds))\n",
    "\n",
    "# Mean square error (MSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improve through experimentation\n",
    "\n",
    "Two of the main methods to improve a models baseline metrics (the first evaluation metrics you get).\n",
    "\n",
    "From a data perspective asks:\n",
    "* Could we collect more data? In machine learning, more data is generally better, as it gives a model more opportunities to learn patterns.\n",
    "* Could we improve our data? This could mean filling in misisng values or finding a better encoding (turning things into numbers) strategy.\n",
    "\n",
    "From a model perspective asks:\n",
    "* Is there a better model we could use? If you've started out with a simple model, could you use a more complex one? (we saw an example of this when looking at the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html), ensemble methods are generally considered more complex models)\n",
    "* Could we improve the current model? If the model you're using performs well straight out of the box, can the **hyperparameters** be tuned to make it even better?\n",
    "\n",
    "**Hyperparameters** are like settings on a model you can adjust so some of the ways it uses to find patterns are altered and potentially improved. Adjusting hyperparameters is referred to as hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to find a model's hyperparameters\n",
    "clf = RandomForestClassifier()\n",
    "clf.get_params() # returns a list of adjustable hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7631578947368421\n",
      "0.7631578947368421\n"
     ]
    }
   ],
   "source": [
    "# Example of adjusting hyperparameters by hand\n",
    "\n",
    "# Split data into X & y\n",
    "X = heart_disease.drop(\"target\", axis=1) # use all columns except target\n",
    "y = heart_disease[\"target\"] # we want to predict y using X\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Instantiate two models with different settings\n",
    "clf_1 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2 = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Fit both models on training data\n",
    "clf_1.fit(X_train, y_train)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate both models on test data and see which is best\n",
    "print(clf_1.score(X_test, y_test))\n",
    "print(clf_2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\pandas\\core\\generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Nissan'\n\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\pandas\\core\\generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Toyota'\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 31\u001b[0m\n\u001b[0;32m     24\u001b[0m rs_clf \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mclf,\n\u001b[0;32m     25\u001b[0m                             param_distributions\u001b[38;5;241m=\u001b[39mgrid,\n\u001b[0;32m     26\u001b[0m                             n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# try 10 models total\u001b[39;00m\n\u001b[0;32m     27\u001b[0m                             cv\u001b[38;5;241m=\u001b[39mKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),  \u001b[38;5;66;03m# using simple 5-fold cross-validation\u001b[39;00m\n\u001b[0;32m     28\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# print out results\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Fit the RandomizedSearchCV version of clf\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mrs_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Find the best hyperparameters\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rs_clf\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1806\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1808\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\pandas\\core\\generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Nissan'\n\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\pandas\\core\\generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Toyota'\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"c:\\Users\\yisakg\\desktop\\sample_project_1\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n"
     ]
    }
   ],
   "source": [
    "# Example of adjusting hyperparameters computationally (recommended)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define a grid of hyperparameters\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "# Ensure X and y are defined and properly formatted\n",
    "# X = ... (your features)\n",
    "# y = ... (your target variable)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1)  # n_jobs set to 1 for compatibility\n",
    "\n",
    "# Setup RandomizedSearchCV with KFold cross-validation\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=10,  # try 10 models total\n",
    "                            cv=KFold(n_splits=5),  # using simple 5-fold cross-validation\n",
    "                            verbose=2)  # print out results\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train)\n",
    "\n",
    "# Find the best hyperparameters\n",
    "print(\"Best hyperparameters:\", rs_clf.best_params_)\n",
    "\n",
    "# Scoring automatically uses the best hyperparameters\n",
    "score = rs_clf.score(X_test, y_test)\n",
    "print(\"Model score:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and reload your trained model\n",
    "You can save and load a model with `pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a model with pickle\n",
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(rs_clf, open(\"rs_random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032786885245902"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a saved pickle model\n",
    "loaded_pickle_model = pickle.load(open(\"rs_random_forest_model_1.pkl\", \"rb\"))\n",
    "\n",
    "# Evaluate loaded model\n",
    "loaded_pickle_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the same with `joblib`. `joblib` is usually more efficient with numerical data (what our models are)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs_random_forest_model_1.joblib']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving a model with joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "# Save a model to file\n",
    "dump(rs_clf, filename=\"gs_random_forest_model_1.joblib\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a saved joblib model\n",
    "loaded_joblib_model = load(filename=\"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032786885245902"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate joblib predictions \n",
    "loaded_joblib_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Putting it all together (not pictured)\n",
    "\n",
    "We can put a number of different Scikit-Learn functions together using `Pipeline`.\n",
    "\n",
    "As an example, we'll use `car-sales-extended-missing-data.csv`. Which has missing data as well as non-numeric data. For a machine learning model to work, there can be no missing data or non-numeric values.\n",
    "\n",
    "The problem we're solving here is predicting a cars sales price given a number of parameters about the car (a regression problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing target values (Price)\n",
    "data = pd.read_csv(\"car-sales-extended-missing-data.csv\")  # Update path as needed\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Define different features and transformer pipelines\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"door\", door_transformer, door_feature),\n",
    "        (\"num\", numeric_transformer, numeric_features)])\n",
    "\n",
    "# Create a preprocessing and modelling pipeline\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                        (\"model\", RandomForestRegressor())])\n",
    "\n",
    "# Split data\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
